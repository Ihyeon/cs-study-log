# Chapter 03 - 데이터 수집과 저장
## 📅 2025-10-08

### 1. 데이터 수집의 이해
- 데이터 수집: 단순히 데이터를 모으는 행위를 넘어, 수집된 데이터를 분석에 적합한 형태로 준비하는 과정
- 신뢰할 수 있는 결과를 도출하기 위해서는 충분한 데이터의 양 뿐만 아니라 품질이 중요
- ISO 8000의 데이터 품질 평가 기준: 정확성, 완전성, 일관성, 유효성, 적시성, 상호운영성

### 2. 데이터의 유형
#### 정형 데이터
- 미리 정의된 스키마에 따라 행과 열로 구성된 테이블 형태로 저장되는 데이터
- 특징: 구조화, 정량적, 관계형 데이터베이스에 적합, 분석 용이
- 한계: 예상치 못한 데이터 유형을 수용하기 어려움, 복잡한 정보의 효과적인 저장이 어려움
#### 비정형 데이터
- 미리 정의된 구조나 스키마 없이 자유로운 형태와 다양한 내용을 담고 있는 데이터
- 특징: 비구조화, 다양한 형태, 저장 및 관리의 어려움, 분석 어려움
- 전체 데이터의 약 80%를 차지하는 것으로 추정
- 다양한 정보와 맥락 포함
#### 반정형 데이터
- 어느 정도의 구조화된 요소를 포함하지만 정형 데이터와 같이 엄격한 스키마나 고정된 형식을 따르지 않음
- 특징: 일정 수준 구조화, 다양한 형태(JSON, 로그 파일 등), 유연성, 분석 방법(NoSQL 데이터베이스 등으로 관리)
- 분석을 위해서는 구조를 파악하고 데이터를 정제하는 추가 과정이 필요

### 3. 데이터 수집 방법
#### 데이터 수집 방법론
- 데이터 소스의 형태, 접근 권한, 데이터 양, 실시간성 요구 등을 고려하여 적절한 수집 방법을 선택
- 파일, 데이터베이스, API, 웹 스크래핑 등 다양한 수집 기술이 존재

#### 파일 기반 데이터 수집
- 데이터 분석의 가장 기본적인 방법 중 하나
- CSV, Excel, JSON, XML 등 다양한 파일 형식 사용
- 일회성 분석이나 배치 처리 방식의 분석에 적합
- pandas 라이브러리는 파일에서 데이터를 효율적으로 읽고 처리하기 위한 기능을 제공

> 파일 형식에 따른 장단점

| 분류 | 형식 | 장점 | 단점 | 주요 용도 |
| :--- | :--- | :--- | :--- | :--- |
| **정형** | CSV | - 높은 범용성<br>- 다양한 프로그램 호환<br>- 간단한 구조<br>- SQL 호환 | - 복잡한 구조 표현 어려움<br>- 바이너리 데이터 저장 불가<br>- 데이터 타입 정보 없음 | - 일회성 분석<br>- 배치 처리 |
| **정형** | Excel | - 시각적 편집 기능<br>- 수식 및 차트 지원<br>- 계층적 구조 표현 | - 프로그래밍 처리 복잡<br>- 용량이 큰 편 | - 비즈니스 리포트<br>- 데이터 편집 |
| **반정형** | JSON | - 웹 API 표준<br>- 가독성 우수 | - 바이너리 데이터 저장 불가<br>- 중첩 구조시 복잡<br>- CSV 대비 용량 큼 | - 웹 API<br>- 설정 파일<br>- NoSQL |
| **반정형**| XML | - 구조화된 데이터 표현<br>- 스키마 검증 | - 파일 오버헤드<br>- JSON 대비 복잡 | - 웹 서비스<br>- 설정 파일 |
| **반정형**| HTML | - 브라우저 호환<br>- 링크 구조 | - 데이터 추출 복잡<br>- 노이즈 많음 | - 웹 스크래핑<br>- 웹 페이지 |
| **비정형**| TXT | - 단순한 구조<br>- 높은 호환성<br>- 용량 효율적 | - 구조화 안됨<br>- 메타데이터 없음<br>- 분석 어려움 | - 로그 파일<br>- 자유 텍스트 |
| **비정형**| LOG | - 시간순 기록<br>- 디버깅 정보<br>- 시스템 추적 | - 정규표현식 필요<br>- 구조 불일치<br>- 노이즈 많음 | - 시스템 모니터링<br>- 에러 분석 |

#### API 기반 데이터 수집
- API: 소프트웨어 간의 상호작용을 가능하게 하는 인터페이스
- REST API 모델: 클라이언트는 서버에 특정 데이터를 요청하고 서버는 이에 반응하여 JSON, XML과 같은 형식의 데이터를 반환
> API 프로토콜의 종류

| 구분 | HTTP / HTTPS | WebSocket | GraphQL |
| :--- | :--- | :--- | :--- |
| **동작 방식** | 요청(request) → 응답(response) | 양방향 통신 (자유로운 데이터 교환) | 쿼리 기반 요청, 필요한 데이터만 선택적 응답 |
| **연결 방식** | 비연결 지향 (요청마다 새로운 연결) | 지속 연결 (handshake 이후 연결 유지) | 단일 엔드포인트 연결, 요청마다 명시적 질의 전송 |
| **장점** | 간단하고 호환성 높음 | 실시간 데이터 전송에 유리 (이벤트 기반) | 과도한 데이터 전송 방지, 유연한 질의 구조 제공 |
| **단점** | 실시간성 부족, 과도한 요청 발생 가능 | 구현 복잡도 높고, HTTP에 비해 지원 환경 제한됨 | 학습 필요, 캐싱 처리 어려움 |
| **활용 예시** | REST API, Open API, 웹 페이지 통신 | 주식 시세, 채팅 앱, 실시간 알림, 게임 서버 등 | 복잡한 앱의 데이터 요청 최적화 (ex. 페이스북, 쇼핑몰) |

#### 웹 스크래핑 기반 데이터 수집
- 프로그램을 통해 웹 사이트에서 데이터를 자동으로 추출하고 수집하는 기능
- 자동화된 방식으로 웹 페이지를 방문하고 링크를 따라 이동하면서 웹의 구조를 탐색하는 웹 크롤링과 구별
- 웹 스크래핑 시 고려사항: 웹 페이지 구조 분석, 데이터 추출 방법, 웹 사이트 정책 준수, 정적 페이지와 동적 페이지
- requests, BeautifulSoup, Selenium, lxml 등 다양한 파이썬 라이브러리 활용

#### 실습
```python
import requests
import json
import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from lxml import html
import time

# CSV 파일 읽기
df = pd.read_csv(
    'data.csv',
    encoding='utf-8',   # encoding='utf-8': 한글 깨짐 방지 (가장 일반적인 인코딩)
    sep=',',            # sep=',': 쉼표로 데이터를 구분 (CSV 파일의 기본값)
    header=0,           # header=0: 첫 번째 행을 컬럼 이름으로 사용 (기본값)
    index_col=None,     # index_col=None: 별도의 인덱스 컬럼을 지정하지 않음 (기본값)
    skiprows=None,      # skiprows=None: 파일 시작 부분에서 건너뛸 행 없음 (기본값)
    nrows=None          # nrows=None: 파일의 모든 행을 읽어옴 (기본값)
)
print(df)

# JSON 파일 읽기
with open('data.json', mode='r', encoding='utf-8') as f:
    data = json.load(f)
print(data)

## JSON 파일의 DataFrame 읽기
df = pd.read_json('data.json', orient='records', encoding='utf-8', lines=False)
print(df)

# 텍스트 파일 읽기
with open('callcenter.log', 'r', encoding='utf-8') as f:
    content = f.read()

## 주민등록번호 패턴 생성
pattern = re.compile(r'(\d{6})-(\d{7})')

## 주민등록번호 마스킹
masked_content = pattern.sub(r'\1-*******', content)

## 마스킹된 텍스트 파일 오픈 및 쓰기
with open('callcenter_masked.log', mode='w') as f:
    f.write(masked_content)
print(masked_content)

# Open-Meteo의 무료 날씨 API를 통한 특정 지역 온도 조회
url = "https://api.open-meteo.com/v1/forecast?=&=&current=temperature_2m"
params = {
    "latitude": "37.58638333",
    "longitude": "127.0203333",
    "current": "temperature_2m"
}

try:
    ## URL 및 파라미터 전송
    response = requests.get(url, params=params)
    response.raise_for_status()

    ## JSON 데이터 읽기
    data = response.json()
except requests.exceptions.RequestException as e:
    print(f"API 호출 실패: {e}")
except json.JSONDecodeError as e:
    print(f"JSON 파싱 실패: {e}")

# Selenium과 lxml을 이용한 웹 스크래핑
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')               ## 브라우저 창 없이 실행
chrome_options.add_argument('--no-sandbox')             ## 보안모드 비활성화 (Colab 필수)
chrome_options.add_argument('--disable-dev-shm-usage')  ## 메모리 부족 방지 (Colab 필수)
chrome_options.add_argument('--window-size=1920x1080')  ## 창 크기 설정(가상)
chrome_options.add_argument('--disable-gpu')            ## GPU 가속 비활성화 (일부 환경 안정성)
chrome_options.binary_location = "/usr/bin/google-chrome-stable"  ## Colab용 크롬 경로 지정

## 드라이버 실행
driver = webdriver.Chrome(service=service, options=chrome_options)

## 사이트 접속
url = 'https://professor.knou.ac.kr/jaehwachung/index.do'
driver.get(url)

## 사이트 접속 대기
time.sleep(2)

## 페이지 제목 출력
page_source = driver.page_source
tree = html.fromstring(page_source)

title_text = tree.xpath('//title/text()')
print(title_text)

## 드라이버 종료
driver.quit()
```

### 4. 데이터 저장의 이해
#### 데이터 저장
- 수집한 데이터를 영구적으로 사용할 수 있도록 적절하게 관리하는 과정
#### 데이터 저장 방식: 파일
- OS의 파일 시스템 상에서 데이터를 독립적인 단위로 저장
- 호환성이 뛰어나고 여러 환경에서 파일 읽기/쓰기 가능
- 대규모 데이터 처리에 비효율적이고 데이터 무결성과 보안 측면에서 취약
- CSV(Comma Separated Version)
  - MS 엑셀, 구글 스프레드시트, 데이터베이스 등 다양한 프로그램과 연동 용이
  - DataFrame은 CSV와 구조적 유사성으로 CSV 파일로 변환하여 저장하는 방법을 제공
- JSON(JavaScript Object Notation)
  - 계층 구조를 가진 데이터 저장에 유용
  - json 또는 pandas 라이브러리를 사용하여 데이터를 JSON 파일로 저장 가능
#### 데이터 저장 방식: 데이터베이스
- 수집한 정보를 효율적으로 보관하고 필요할 때 신속하게 활용하기 위한 체계적인 저장 시스템
- RDBMS: 데이터를 행과 열로 구성된 테이블 형태로 저장하고 SQL을 통해 데이터의 CRUD 수행
- 비RDBMS: 문서, 키-값의 쌍, 그래프 등 다양한 유연한 방식의 저장 구조를 지원하고 유사 SQL 및 API를 통해 조작

### 5. PandasDataFrame의 이해
#### DataFrame
- 구조: 2차원 테이블 형태의 자료구조
- 인덱스: 생성 시 정수형 인덱스가 자동 부여(set_index() 메소드로 변경 가능)
- 데이터는 내부에 Numpy의 배열 형태로 저장(고속의 수치 연산 수행)
```python
import pandas as pd

data = {
    "이름": ["김철수", "이영희", "박민수", "최지훈"],
    "학년": [1, 2, 3, 4],
    "학점": [4.2, 3.8, 4.5, 3.9],
    "학과": ["컴퓨터학", "경영학", "농학", "교육학"],
    "동아리": ["프로그래밍", "독서", "로봇", "봉사"]
}
df = pd.DataFrame(data)

print("index:\n", df.index)
print("\ncolumns:\n", df.columns)
print("\nvalues:\n", df.values)
print("\nrows:\n", df.values.tolist())
```
#### DataFrame 생성 함수
| 데이터 유형 | 메소드명 | 설명 |
| :--- | :--- | :--- |
| 딕셔너리 | `from_dict()` | 딕셔너리를 변환. 키는 열 이름, 값은 열 데이터로 설정 |
| 시퀀스(리스트, 튜플, 딕셔너리) | `from_records()` | 레코드(리스트, 튜플, 딕셔너리)의 시퀀스를 변환 |
| CSV | `read_csv()` | CSV 파일에서 변환 |
| JSON | `read_json()` | JSON 파일 / 문자열에서 변환 |
| 엑셀 파일 | `read_excel()` | 엑셀 파일에서 변환 |
| HTML | `read_html()` | HTML 테이블 데이터를 변환 |
| 클립보드 | `read_clipboard()` | 클립보드(복사한 데이터)에서 변환 |
| 관계형 DB | `read_sql()` | SQL 결과 또는 DB 테이블에서 변환 |

#### DataFrame 저장 함수
| 메소드 | 설명 |
| :--- | :--- |
| `to_csv()` | CSV 파일로 저장 |
| `to_json()` | JSON 파일 또는 JSON 문자열로 저장 |
| `to_excel()` | 엑셀 파일(.xlsx)로 저장 |
| `to_html()` | HTML 테이블 형식으로 변환 |
| `to_sql()` | 관계형 데이터베이스(SQL 테이블)로 저장 |
| `to_clipboard()` | 클립보드에 복사 |
| `to_dict()` | 파이썬 딕셔너리(dictionary)로 변환 |
| `to_string()` | 문자열로 변환하여 출력 |
| `to_markdown()` | 마크다운(markdown) 형식의 문자열로 변환 |
